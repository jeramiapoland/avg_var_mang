%The choice of the estimation window size has always been a concern for practitioners, since the use of different window sizes may lead to different empirical results in practice. In addition, arbitrary choices of window sizes have consequences about how the sample is split into in-sample and out-of-sample portions. Notwithstanding the importance of the problem, no satisfactory solution has been proposed so far, and in the forecasting literature, it is common to only report empirical results for one window size.
Out of sample estimation always raises issues with the choices made in the specification of the model and how to split the data into in and out of sample windows. 
%A first concern is that the “ad-hoc” window size used by the researcher may not detect significant predictive ability even if there would be significant predictive ability for some other window size choices. A second concern is the possibility that satisfactory results were obtained simply by chance, after data snooping over window sizes. That is, the successful evidence in favor of predictive ability might have been found after trying many window sizes, although only the results for the successful window size were reported and the search process was not taken into account when evaluating their statistical significance.
Bluntly speaking, there are no good answers. The standard practice as in \citet{Rapach2013},\citet{Rapach2010}, \citet{Rapach2016}, and \cite{Huang2015}, and many others, is to show performance in a few subsamples split by dates that the authors choose for unknown reasons. The concerns with subsample selection are that the window may either be "ad-hoc" and the selection may mask significant results that would appear if the subsamples had been constructed differently. A second, more cynical, concern is that the presented subsample represent significant performance that has been found either by chance or as the result of analyzing many subsample and only presenting the significant results. In any case, evaluation of the differences in performance across subsamples is often left to the imagination of the reader and whatever importance they place on the first half of the sample versus the second, the middle third versus the first and last thirds or however the data has been separated. 

To avoid these issues first I present subsample results splitting the out of sample prediction window between NBER defined business cycle contractions and expansion. The purpose of this is to contrast the performance of the AV and SV based forecasts when returns are generally expected to be positive and when they are negative. These are particularly meaningful subsamples for AV, AC and SV. As \citet{Forbes_2002}, \citet{Hartmand_2004}, and \citet{ANG2002443} and many others have demonstrated the correlation between equity returns increases during crises and market downturns and decreases during upturns. As average correlation, average variance and market variance are all related by definition, contractions are likely to affect the predictive performance of AV and SV differently than expansions.

Panel A of table \ref{tab_robust}

This indicates that average correlation is a better performing predictor in times of crises as suggested by the its best performance in \cite{pollet_average_2010} in subsamples dominated by recessions.\footnote{Average correlation predicts excess returns best in the 1974 to 1985 and 1996 to 2007 subsamples. These 80 quarters contain all of the 18 contraction quarters from 1974 to 2007. Average correlation is insignificant in the 1986 to 1995 subsample.} 

To further address the robustness of the out of sample results and avoid the use of subsampling completely, I present encompassing statistics robust to both the specification of the prediction model, either expanding or rolling, and the choice of prediction window. \cite{rossi_out--sample_2012} presents out of sample statistics robust to the choice of split between in and out of sample periods. 

