%The choice of the estimation window size has always been a concern for practitioners, since the use of different window sizes may lead to different empirical results in practice. In addition, arbitrary choices of window sizes have consequences about how the sample is split into in-sample and out-of-sample portions. Notwithstanding the importance of the problem, no satisfactory solution has been proposed so far, and in the forecasting literature, it is common to only report empirical results for one window size.
Out of sample estimation always raises issues with the choices made in the specification of the model and how to split the data into in and out of sample windows. 
%A first concern is that the “ad-hoc” window size used by the researcher may not detect significant predictive ability even if there would be significant predictive ability for some other window size choices. A second concern is the possibility that satisfactory results were obtained simply by chance, after data snooping over window sizes. That is, the successful evidence in favor of predictive ability might have been found after trying many window sizes, although only the results for the successful window size were reported and the search process was not taken into account when evaluating their statistical significance.
Bluntly speaking, there are no good answers. The standard practice as in \citet{Rapach2013}, \citet{Rapach2010}, \citet{Rapach2016}, and \cite{Huang2015}, and many others, is to show performance in a few sub-samples split by dates that the authors choose. One of the concerns with sub-sample selection is that the window may be "ad-hoc" and the selection may mask significant results that would appear if the sub-samples had been constructed differently. A second, more cynical, concern is that the presented sub-sample may represent significant performance that has been found either by chance or as the result of analyzing many sub-sample and only presenting the significant results. In any case, evaluation of the differences in performance across sub-samples is often left to the imagination of the reader and whatever importance they place on the first half of the sample versus the second, the middle third versus the first and last thirds or however the data has been separated. While the selection of 1962 is not arbitrary, we have seen already a difference in return prediction performance for AV between the period after 1962 and the whole data set starting in 1926 which raises the question of the robustness of the out-of-sample results. Is the lack of significance in the pre-1962 data indicative of instability, or worse, is the relationship between AC, AV and future risk and returns or is this simply type II error, a lack of result in a specific sub-sample for a specific regression specification? Are the strong out-of-sample results for the AV predictions of future risk and return type I error, the result of a favorable data and regression specification leading to significance where none actually exists? To resolve these issues we need out-of-sample results robust to the data window specification. 

%To avoid these issues first I present sub-sample results splitting the out of sample prediction window between NBER defined business cycle contractions and expansion. The purpose of this is to contrast the performance of the AV and SV based forecasts when returns are generally expected to be positive and when they are negative. These are particularly meaningful sub-samples for AV, AC and SV. As \citet{Forbes_2002}, \citet{Hartmand_2004}, and \citet{ANG2002443} and many others have demonstrated the correlation between equity returns increases during crises and market downturns and decreases during upturns. As average correlation, average variance and market variance are all related by definition, contractions are likely to affect the predictive performance of AV and SV differently than expansions.

%Panel A of table \ref{tab_robust}

%This indicates that average correlation is a better performing predictor in times of crises as suggested by the its best performance in \cite{pollet_average_2010} in sub-samples dominated by recessions.\footnote{Average correlation predicts excess returns best in the 1974 to 1985 and 1996 to 2007 sub-samples. These 80 quarters contain all of the 18 contraction quarters from 1974 to 2007. Average correlation is insignificant in the 1986 to 1995 sub-sample.} 

To address the robustness of the out of sample results, I use out-of-sample statistics robust to both the specification of the prediction model, either expanding or rolling, and the choice of prediction window. \cite{rossi_out--sample_2012} formulate out of sample statistics robust to the choice of split between in and out of sample periods and regression specification. The paper presents the calculation of the \citet{Diebold1995} statistic and the \citet{harvey_tests_1998} encompassing test such that the choice of out-of-sample starting period is eliminated as a nuisance parameter and the asymptotic behavior of the statistics can be used to measure their observed significance. Fundamentally, this involves the calculation of each of the statistics for all feasible out-of-sample windows and in the case of rolling regression specification all feasible window sizes. The modifications are different for each of the statistics and the calculation of the robust statistic is different depending both on which statistic and which concern is being addressed. When the concern is that the chosen window could be overly optimal, perhaps the best results of many tests, then it is possible that the null of no improvement is rejected based on the calculated statistics when in general it is true. To eliminate this possibility, \citet{rossi_out--sample_2012} provide the $R_{T}$ measure which essentially insures that the highest calculated statistic is so extreme that it could not occur without a underlying significant improvement in forecast accuracy over the benchmark model. The $A_{T}$ measure insures that the average calculated statistic is large enough that an arbitrarily selected out-of-sample starting period would not lead to the failure to reject the null of no accuracy improvement when it was indeed false. This two measures tackle the type I and II error questions. Given the results thus far, we will be looking for significant $R_{T}$ values to support the significant ability of AV to predict stock market returns, SV and AV across the data set, and significant $A_{T}$ values to tell us that the significant ability of AV to predict log excess returns, seen from 1970 forward, is indicative of a real accuracy improvement while the lack of performance when including predictions from 1939 forward is simply a noisy period of poor performance obfuscating the superiority of the AV based model.
%\bigskip
%\centerline{\bf [Place Table~\ref{tab:tab_out_sample_robust} about here]}
%\bigskip

Table \ref{tab:tab_out_sample} panel (c) shows the robust out-of-sample statistics. The $R_{T}$ and $A_{T}$ statistics for the comparison of all possible expanding window forecasting models using AV with in-sample training windows of at least 15\% of the data and out-of-sample forecasting periods of at least 15\% of the data against a benchmark model using SV with the same specifications. The proportional data cut offs are necessary to use the critical values provided in the \citet{rossi_out--sample_2012} paper, 15\% is the smallest, and mean that the first feasible specification starts forecasting in December 1939 as in the out-of-sample results shown above and forecasts for at least April 2003 to December 2016 are made. Every DM statistic is significant indicating that the AV model is an improvement in forecasting accuracy for all variable of interest. Every encompassing test statistic is significant, however these are not $\lambda$ values directly so while we know that AV contains information over and above SV they do not directly indicate it is optimal alone. The results for comparisons of rolling window specification tests are shown in the appendix. Overall, the out-of-sample results show that AV is a better signal of the dynamic risk-return trade-off. The relationships between AC and AV, compensated systematic risk and uncompensated, are robust to model specification and testing construction through out the full sample.
%AV and SV models, again using the 15\% proportional cut-offs. While all DM statistics are significant, not all encompassing tests are. There are too many rolling window specifications in which SV contains significant forecasting information which is not captured by AV. A forecast combining the values from rolling window models using AV and SV will almost surely be better than using either rolling window forecast alone while using the expanding window AV model forecast alone may very well be better compared to any combination of that prediction with an expanding window SV forecast.

Regression results, both in-sample and out-of-sample, support the performance results detailed before. There is a robust dynamic relationship between AV and future risk. AV is more informative than SV of changes in future risk and return. The AV managed return performance, in US equities, in global equities, and across asset classes is backed by signals of changes in the dynamic mix of compensated and uncompensated risk.