%The choice of the estimation window size has always been a concern for practitioners, since the use of different window sizes may lead to different empirical results in practice. In addition, arbitrary choices of window sizes have consequences about how the sample is split into in-sample and out-of-sample portions. Notwithstanding the importance of the problem, no satisfactory solution has been proposed so far, and in the forecasting literature, it is common to only report empirical results for one window size.
Out of sample estimation always raises issues with the choices made in the specification of the model and how to split the data into in and out of sample windows. 
%A first concern is that the “ad-hoc” window size used by the researcher may not detect significant predictive ability even if there would be significant predictive ability for some other window size choices. A second concern is the possibility that satisfactory results were obtained simply by chance, after data snooping over window sizes. That is, the successful evidence in favor of predictive ability might have been found after trying many window sizes, although only the results for the successful window size were reported and the search process was not taken into account when evaluating their statistical significance.
Bluntly speaking, there are no good answers. The standard practice as in \citet{Rapach2013}, \citet{Rapach2010}, \citet{Rapach2016}, and \cite{Huang2015}, and many others, is to show performance in a few subsamples split by dates that the authors choose for unknown reasons. The concerns with subsample selection are that the window may either be "ad-hoc" and the selection may mask significant results that would appear if the subsamples had been constructed differently. A second, more cynical, concern is that the presented subsample represent significant performance that has been found either by chance or as the result of analyzing many subsample and only presenting the significant results. In any case, evaluation of the differences in performance across subsamples is often left to the imagination of the reader and whatever importance they place on the first half of the sample versus the second, the middle third versus the first and last thirds or however the data has been separated. While the selection of 1962 is not arbitary as the daily return data is of much higher quality after, we have seen already a difference in return prediction performance for AV between the period after 1962 and the whole data set starting in 1926 which raises the question of the robustness of the out-of-sample results. 

%To avoid these issues first I present subsample results splitting the out of sample prediction window between NBER defined business cycle contractions and expansion. The purpose of this is to contrast the performance of the AV and SV based forecasts when returns are generally expected to be positive and when they are negative. These are particularly meaningful subsamples for AV, AC and SV. As \citet{Forbes_2002}, \citet{Hartmand_2004}, and \citet{ANG2002443} and many others have demonstrated the correlation between equity returns increases during crises and market downturns and decreases during upturns. As average correlation, average variance and market variance are all related by definition, contractions are likely to affect the predictive performance of AV and SV differently than expansions.

%Panel A of table \ref{tab_robust}

%This indicates that average correlation is a better performing predictor in times of crises as suggested by the its best performance in \cite{pollet_average_2010} in subsamples dominated by recessions.\footnote{Average correlation predicts excess returns best in the 1974 to 1985 and 1996 to 2007 subsamples. These 80 quarters contain all of the 18 contraction quarters from 1974 to 2007. Average correlation is insignificant in the 1986 to 1995 subsample.} 

To address the robustness of the out of sample results and avoid the use of subsampling completely, I present out-of-sample statistics robust to both the specification of the prediction model, either expanding or rolling, and the choice of prediction window. \cite{rossi_out--sample_2012} presents out of sample statistics robust to the choice of split between in and out of sample periods. The paper presents the calculation of the \citet{Diebold1995} statistic and the \citet{harvey_tests_1998} encompassing test such that the choice of out-of-sample starting period is eliminated as a nuisance parameter and the asymptotic behavior of the statistics can be used to measure their observed significance. Fundamentally, this involves the calculation of each of the statistics for all feasible out-of-sample windows and in the case of rolling regression specification all feasible window sizes. The modifications are different for each of the statistics and the calculation of the robust statistic is different depending both on which statistic and which concern is being addressed. When the conern is that the choosen window could be unrepresentatively optimal, perhaps the best results of many tests, then it is possible that the null of no imporovement is rejected based on the calculated statistics when in general it is true. To eliminate this possibility, \citet{rossi_out--sample_2012} provide the $R_{T}$ measure which essentially insures that the highest calculated statistics are so extreme that they could not occur without a underlying significant improvement in forecast accuracy from the benchmark to the proposed model. The $A_{T}$ measure insures that the average calculated statistics are large enough that an arbitrarily selected out-of-sample starting period would not lead to the failure to reject the null of no accuracy improvement when it was indeed false. This two measures tackle the type I and II error questions. Given the results thus far, we will be looking for significant $R_{T}$ values to support the significant ability of AV to predict stock market and average variance across the data set, and significant $A_{T}$ values to tell us that the significant ability of AV to predict log excess returns, seen from 1970 forward, is indicative of a real accuracy improvement while the lack of performance when including predictions from 1939 forward is simply a noisy period of poor performance obfuscating the superiority of the AV based model.

Table \ref{tab:tab_out_sample_robust} shows the robust out-of-sample statistics. Panel A has the $R_{T}$ and $A_{T}$ statistics for the comparision of all possible expanding window forecasting models using AV with in-sample training windows of at least 15\% of the data and out-of-sample forecasting periods of at least 15\% of the data against a benchmark model using SV with the same specifictions. The porportional data cut offs are necessary to use the critical values provided in the \citet{rossi_out--sample_2012} paper, 15\% is the smallest, and mean that the first feasible specification starts forecasting in December 1939 as in the out-of-sample results shown above and forecasts for at least April 2003 to December 2016 are made. Every DM statistic is significant indicating that the AV model is a significant improvment in forecasting accuracy for all variable of interest. Every encompassing test statistic is significant, however these are not $\lambda$ values directly so while we know that AV contains information over and above SV they do not directly indicate it is optimal alone. Panel B has the results for comparisons of rolling window specification tests of AV and SV models, again using the 15\% proportional cut-offs. While all DM statistics are significant, not all encompassing tests are. There are too many rolling window specifications in which SV contains significant forecasting information which is not captured by AV. A forecast combining the values from rolling window models using AV and SV will almost surely be better than using either rolling window forecast alone while using the expanding window AV model forecast alone may very well be better compared to any combination of that prediction with an expanding window SV forecast.